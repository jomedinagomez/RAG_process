{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc, struct\n",
    "from azure import identity\n",
    "from faker import Faker\n",
    "from typing import Union\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "connection_string = os.environ[\"AZURE_SQL_CONNECTIONSTRING\"]\n",
    "\n",
    "SQL_SERVER_USERNAME = os.environ[\"SQL_SERVER_USERNAME\"]\n",
    "SQL_SERVER_ENDPOINT = os.environ[\"SQL_SERVER_ENDPOINT\"]\n",
    "SQL_SERVER_PASSWORD = os.environ[\"SQL_SERVER_PASSWORD\"]\n",
    "SQL_SERVER_DATABASE = os.environ[\"SQL_SERVER_DATABASE\"] \n",
    "driver = \"{ODBC Driver 18 for SQL Server}\"\n",
    "sqlalchemy_driver = \"ODBC Driver 18 for SQL Server\"\n",
    "\n",
    "## Creatng a connection to the SQL Server\n",
    "conn = pyodbc.connect(f'DRIVER={driver};SERVER={SQL_SERVER_ENDPOINT};PORT=1433;DATABASE={SQL_SERVER_DATABASE};UID={SQL_SERVER_USERNAME};PWD={SQL_SERVER_PASSWORD}')  \n",
    "cursor = conn.cursor()\n",
    "\n",
    "#https://github.com/Azure-Samples/openai/blob/main/End_to_end_Solutions/AOAISearchDemo/scripts/prepopulate/populate_sql.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = \"../../../../data/processed/files/\"\n",
    "files = os.listdir(relative_path)\n",
    "\n",
    "df = pd.concat([pd.read_parquet(relative_path+file) for file in files]).reset_index(drop=True)\n",
    "df['title_vector'] = df['title_vector'].apply(lambda x: x.tolist())\n",
    "df['content_vector'] = df['content_vector'].apply(lambda x: x.tolist())\n",
    "df['id'] = df['chunk_id']\n",
    "\n",
    "CONTAINER_ID = df['preprocessing_pipeline'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save CSV files as tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create other SQL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE Customers (\n",
    "  cust_id INTEGER,\n",
    "  cust_name VARCHAR(1000),\n",
    "  cust_email VARCHAR(1000),\n",
    "  cust_phone VARCHAR(1000),\n",
    "  cust_address VARCHAR(1000),\n",
    "  PRIMARY KEY (cust_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Products (\n",
    "  prod_id INTEGER,\n",
    "  prod_name VARCHAR(1000),\n",
    "  price FLOAT,\n",
    "  category VARCHAR(1000),\n",
    "  PRIMARY KEY (prod_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Merchants (\n",
    "  merchant_id INTEGER,\n",
    "  merchant_name VARCHAR(1000),\n",
    "  merchant_region VARCHAR(1000),\n",
    "  merchant_address VARCHAR(1000),\n",
    "  PRIMARY KEY (merchant_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Stock (\n",
    "  prod_id INTEGER,\n",
    "  merchant_id INTEGER,\n",
    "  stock INTEGER,\n",
    "  PRIMARY KEY (prod_id, merchant_id),\n",
    "  FOREIGN KEY (merchant_id) REFERENCES Merchants(merchant_id),\n",
    "  FOREIGN KEY (prod_id) REFERENCES Products(prod_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Sales (\n",
    "    sale_id INTEGER,\n",
    "    cust_id INTEGER,\n",
    "    merchant_id INTEGER,\n",
    "    date DATETIME,\n",
    "    total_price FLOAT,\n",
    "    PRIMARY KEY (sale_id),\n",
    "    FOREIGN KEY (cust_id) REFERENCES Customers(cust_id),\n",
    "    FOREIGN KEY (merchant_id) REFERENCES Merchants(merchant_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE Sales_Detail (\n",
    "  sales_id INTEGER,\n",
    "  prod_id INTEGER,\n",
    "  quantity INTEGER,\n",
    "  PRIMARY KEY (sales_id, prod_id),\n",
    "  FOREIGN KEY (sales_id) REFERENCES Sales(sale_id),\n",
    "  FOREIGN KEY (prod_id) REFERENCES Products(prod_id)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSVToSQL(table_name,file_location):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_location)\n",
    "    for index, row in df.iterrows():\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name} ({', '.join(df.columns)})\n",
    "        VALUES ({', '.join(['?' for _ in df.columns])})\n",
    "        \"\"\"\n",
    "        cursor.execute(insert_query, tuple(row))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = \"../../../../data/processed/structured/\"\n",
    "files = os.listdir(relative_path)\n",
    "\n",
    "CSVToSQL(\"Customers\",relative_path+'/customers.csv')\n",
    "CSVToSQL(\"Products\",relative_path+'/products.csv')\n",
    "CSVToSQL(\"Merchants\",relative_path+'/merchants.csv')\n",
    "CSVToSQL(\"Stock\",relative_path+'/stock.csv')\n",
    "CSVToSQL(\"Sales\",relative_path+'/sales.csv')\n",
    "CSVToSQL(\"Sales_Detail\",relative_path+'/sales_detail.csv')\n",
    "\n",
    "cursor.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secdemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
