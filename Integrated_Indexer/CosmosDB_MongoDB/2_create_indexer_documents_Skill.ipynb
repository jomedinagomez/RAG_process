{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "AZURE_SEARCH_ADMIN_CREDENTIAL = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")) if os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") else DefaultAzureCredential()\n",
    "index_name = \"pull-cosmosdb-nosql-chunk-index\"\n",
    "\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-small\")\n",
    "azure_openai_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\", \"text-embedding-3-small\")\n",
    "azure_openai_model_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 1536))\n",
    "\n",
    "# note: The chat deployment should support tool use\n",
    "# To learn more, please see\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35\n",
    "azure_openai_chat_deployment = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"gpt-4o-mini\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2024-07-01-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pull-cosmosdb-nosql-chunk-index created\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIParameters,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex,\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchIndexerSkillset,\n",
    "    SearchIndexerIndexProjectionSelector,  \n",
    "    SearchIndexerIndexProjections,  \n",
    "    SearchIndexerIndexProjectionsParameters, \n",
    "    IndexProjectionMode,\n",
    "    AzureOpenAIEmbeddingSkill\n",
    ")\n",
    "\n",
    "# Create a search index\n",
    "# note: You must adjust these fields based on your CSV Schema.\n",
    "# There is no chunking of the description or title fields in this sample.\n",
    "# There is a separate AzureSearch_DocumentKey for the key automatically generated by the indexer\n",
    "# Learn more at https://learn.microsoft.com/en-us/azure/search/search-howto-index-json-blobs\n",
    "\n",
    "\n",
    "## ['title', 'header', 'content', 'summary', 'title_vector','content_vector', 'unique_id']\n",
    "       \n",
    "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE_ENDPOINT, credential=AZURE_SEARCH_ADMIN_CREDENTIAL)  \n",
    "fields = [  \n",
    "    SearchField(name=\"id\",  key=True, type=SearchFieldDataType.String,analyzer_name=\"keyword\"),\n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"header\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"section\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"unique_id\", type=SearchFieldDataType.String, sortable=False, filterable=True, facetable=False, analyzer_name=\"keyword\"),\n",
    "    #SearchField(name=\"summary\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),    \n",
    "    #SearchField(name=\"title_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "    SearchField(name=\"SectionVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=azure_openai_model_dimensions, vector_search_profile_name=\"myHnswProfile\"),\n",
    "]  \n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
    "                resource_uri=azure_openai_endpoint,  \n",
    "                deployment_id=azure_openai_embedding_deployment,\n",
    "                model_name=azure_openai_model_name,\n",
    "                api_key=azure_openai_key,\n",
    "            ),\n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        content_fields=[SemanticField(field_name=\"section\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create the semantic search with the configuration  \n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
    "  \n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or update CosmosDB data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'searchdemocdbnosql' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SoftDeleteColumnDeletionDetectionPolicy\n",
    ")\n",
    "\n",
    "\n",
    "AZURE_COSMOS_DB_ENDPOINT= os.environ[\"AZURE_COSMOS_DB_ENDPOINT\"]\n",
    "AZURE_COSMOS_DB_KEY= os.environ[\"AZURE_COSMOS_DB_KEY\"]\n",
    "AZURE_COSMOS_DB_DATABASE= os.environ[\"AZURE_COSMOS_DB_DATABASE\"]\n",
    "AZURE_COSMOS_DB_CONTAINER= os.environ[\"AZURE_COSMOS_DB_CONTAINER\"]\n",
    "AZURE_COSMOS_DB_CONN= os.environ[\"AZURE_COSMOS_DB_CONN\"]\n",
    "AZURE_COSMOS_DB_DATASOURCE_NAME  =  os.environ[\"AZURE_COSMOS_DB_DATASOURCE_NAME\"]\n",
    "\n",
    "\n",
    "# Create a data source\n",
    "# NOTE: To remove records from a search index, add a column to the row \"IsDeleted\" set to \"True\". The next indexer run will remove this record\n",
    "# To learn more please visit https://learn.microsoft.com/en-us/azure/search/search-howto-index-one-to-many-blobs\n",
    "indexer_client = SearchIndexerClient(AZURE_SEARCH_SERVICE_ENDPOINT, AZURE_SEARCH_ADMIN_CREDENTIAL)\n",
    "container = SearchIndexerDataContainer(name=AZURE_COSMOS_DB_CONTAINER)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=AZURE_COSMOS_DB_DATASOURCE_NAME,\n",
    "    type=\"cosmosdb\",\n",
    "    connection_string=AZURE_COSMOS_DB_CONN,\n",
    "    container=container,\n",
    "    data_deletion_detection_policy=SoftDeleteColumnDeletionDetectionPolicy(soft_delete_column_name=\"IsDeleted\", soft_delete_marker_value=\"True\")\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a skillset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pull-cosmosdb-nosql-chunk-index-skillset created\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "  \n",
    "split_skill = SplitSkill(\n",
    "        description=\"Split skill to chunk documents\",\n",
    "        text_split_mode=\"pages\",\n",
    "        context=\"/document\",\n",
    "        maximum_page_length=400,\n",
    "        page_overlap_length=50,\n",
    "        inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/content\")],\n",
    "        outputs=[OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")],\n",
    "    )\n",
    "\n",
    "title_embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate title embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_uri=azure_openai_endpoint,  \n",
    "    deployment_id=azure_openai_embedding_deployment,  \n",
    "    model_name=azure_openai_model_name,\n",
    "    dimensions=azure_openai_model_dimensions,\n",
    "    api_key=azure_openai_key,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"SectionVector\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "index_projections = SearchIndexerIndexProjections(  \n",
    "    selectors=[\n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,\n",
    "            parent_key_field_name=\"unique_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"section\", source=\"/document/pages/*\"),\n",
    "                InputFieldMappingEntry(name=\"SectionVector\", source=\"/document/pages/*/SectionVector\"),\n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/title\"),\n",
    "                InputFieldMappingEntry(name=\"header\", source=\"/document/header\"),\n",
    "                InputFieldMappingEntry(name=\"unique_id\", source=\"/document/unique_id\"),\n",
    "            ],  \n",
    "        )\n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS    \n",
    "    ),\n",
    ")  \n",
    "\n",
    "skills = [split_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=skills,\n",
    "    index_projections=index_projections,\n",
    ")\n",
    "  \n",
    "indexer_client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    FieldMapping,\n",
    "    FieldMappingFunction,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    BlobIndexerParsingMode\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "indexer_parameters = IndexingParameters(batch_size=None,max_failed_items=0, max_failed_items_per_batch=0)\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\", \n",
    "    skillset_name=skillset_name,   \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters,\n",
    ")  \n",
    "\n",
    "indexer_client = SearchIndexerClient(AZURE_SEARCH_SERVICE_ENDPOINT, AZURE_SEARCH_ADMIN_CREDENTIAL)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f'{indexer_name} is created and running. If queries return no results, please wait a bit and try again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secdemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
